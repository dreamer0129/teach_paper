steer  驾驭:
尿不湿重复，茅台实收金额为负数，246631没有商品名称

大尾巴龙:
茅台倒扣，还有个商品名称缺失

X:
小森林尿不湿的时间，茅台金额，

合群青:
重复数据尿不湿，还有名称缺失，茅台收费金额

合群青:
茅台也不会这么便宜（确信）

合群青:
在微信群组讨论中，关于Min-Max规范化、小数定标规范化和Z-Score规范化这三类方法的优缺点，可以从以下几个方面进行分析：

### 1. Min-Max规范化
**优点：**
- **简单易懂**：公式直观，计算简单，容易实现。
- **结果范围固定**：规范化后的数据范围在[0, 1]或[-1, 1]之间，便于比较和理解。
- **适用于均匀分布**：对于数据分布较为均匀的情况，Min-Max规范化效果较好。

**缺点：**
- **对异常值敏感**：如果数据中存在极端值（极大或极小），规范化后的结果可能会受到影响，导致数据分布不均匀。
- **不适合非均匀分布**：对于数据分布不均匀的情况，Min-Max规范化可能会导致数据失真。

### 2. 小数定标规范化
**优点：**
- **简单易行**：通过移动小数点的位置来实现规范化，计算简单。
- **适用于大范围数据**：对于数据范围较大的情况，小数定标规范化可以有效压缩数据范围。

**缺点：**
- **依赖数据范围**：规范化效果依赖于数据的最大值，如果数据范围变化较大，规范化结果可能不稳定。
- **对异常值敏感**：如果数据中存在极端值，小数定标规范化可能会受到影响。

### 3. Z-Score规范化
**优点：**
- **不受数据范围限制**：Z-Score规范化基于数据的均值和标准差，不受数据范围的影响。
- **适用于正态分布**：对于符合正态分布的数据，Z-Score规范化效果较好。
- **对异常值不敏感**：由于使用了标准差，Z-Score规范化对异常值的敏感度较低。

**缺点：**
- **计算复杂**：相比Min-Max和小数定标规范化，Z-Score规范化计算较为复杂，需要计算均值和标准差。
- **结果范围不固定**：规范化后的数据范围不固定，可能包含负值，不易于直观理解。

### 总结
- **Min-Max规范化**适用于数据分布均匀且无极端值的情况，简单易用但容易受异常值影响。
- **小数定标规范化**适用于数据范围较大的情况，计算简单但对异常值敏感。
- **Z-Score规范化**适用于正态分布的数据，对异常值不敏感但计算复杂。

在实际应用中，可以根据数据的特点和需求选择合适的规范化方法。

X:
min-max，如果最大值是异常值你不炸了？

合群青:
第三种对异常不敏感

合群青:
标准差

大尾巴龙:
Min-Max 规范化
优点：
计算简单，只需知道数据的最大值和最小值。
可将数据缩放到 [0, 1] 区间，便于比较和分析。
当新样本未超出原数据范围时，无需重新计算。
缺点：
对离群值非常敏感，最大值或最小值的变化会导致重新计算。
不适用于数据分布不均匀的场景。
无法处理负值或极端值。
小数定标规范化
优点：
操作简单，计算量小。
不改变数据的分布和形状，保留原始数据的比例关系。
适用范围广，受数据分布影响小。
缺点：
最大值和最小值容易受异常点影响。
鲁棒性较差，不适用于离散数据。
在数据分布极不均匀时可能导致信息丢失。
Z-Score 标准化
优点：
对离群值敏感度低，适用于包含异常值的数据。
消除数据量纲影响，保证数据间的可比性。
适用于数据分布接近正态分布的情况。
缺点：
需要计算均值和标准差，计算过程相对复杂。
对数据分布有一定要求，非正态分布时效果不佳。
标准化后的数据失去了原始意义，需还原才能解释。

steer  驾驭:
网络爬虫虽然是一种强大的数据采集工具，但其使用可能带来以下风险：

---

### **1. 法律风险**  
- **隐私侵权**：抓取未经授权的个人信息（如姓名、联系方式、地址等）可能违反《个人信息保护法》或《通用数据保护条例》（GDPR），导致法律追责。  
- **版权侵犯**：未经许可抓取受版权保护的内容（如文章、图片、视频）可能构成侵权。  
- **违反服务条款**：许多网站的用户协议明确禁止自动化抓取，违反条款可能面临诉讼或索赔。  

---

### **2. 技术风险**  
- **服务器负载过大**：高频或并发的爬虫请求可能导致目标网站服务器过载，甚至瘫痪，引发服务中断。  
- **IP封禁**：网站可能通过检测异常流量封禁爬虫的IP地址或账号，导致数据采集失败。  
- **反爬机制应对成本**：复杂反爬手段（验证码、动态加载、行为分析）需要投入额外资源破解，增加技术复杂度。  

---

### **3. 道德与合规风险**  
- **数据滥用**：抓取的数据可能被用于不正当用途（如诈骗、骚扰、商业间谍），损害他人利益。  
- **破坏公平竞争**：大规模抓取竞争对手的公开数据（如价格、评论）可能被视为不正当竞争。  

---

### **4. 数据质量风险**  
- **结构化数据失效**：网站改版或页面结构调整可能导致原有爬虫解析规则失效，需频繁维护。  
- **信息不完整**：动态加载（JavaScript渲染）或登录限制的内容可能无法被传统爬虫捕获。  
- **脏数据干扰**：目标网站的错误数据或噪声（如广告、重复内容）可能污染采集结果。  

---

### **5. 安全风险**  
- **恶意代码感染**：抓取未经验证的网站时，可能下载包含恶意脚本或病毒的文件，威胁本地系统安全。  
- **数据泄露**：存储不当的爬取数据可能被黑客窃取，导致敏感信息外泄。  

---

### **6. 资源与成本风险**  
- **带宽与存储开销**：大规模抓取需要消耗大量带宽和存储资源，成本可能超出预期。  
- **维护成本高**：需持续监控爬虫运行状态、更新反反爬策略，长期投入较高。  

---

### **应对建议**  
- **遵守法律法规**：明确目标网站的 `robots.txt` 协议，获取数据前确认合法性。  
- **控制请求频率**：设置合理的爬取间隔（如添加延迟），避免对服务器造成压力。  
- **数据脱敏处理**：对抓取的敏感信息进行匿名化或加密存储。  
- **使用代理池和分布式技术**：分散请求IP，降低被封禁风险。  
- **尊重网站权益**：优先通过API等官方渠道获取数据，或在必要时与网站方协商授权。  

合理使用爬虫技术，平衡效率与合规性，是规避风险的关键。
